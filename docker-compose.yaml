services:
  airflow:
    image: apache/airflow:2.8.0
    environment:
      - AIRFLOW_HOME=/opt/airflow
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__WEBSERVER__SECRET_KEY=ml-pipeline-secret-key
      - _PIP_ADDITIONAL_REQUIREMENTS=pandas scikit-learn pydantic pyyaml joblib mlflow numpy
      - _AIRFLOW_WWW_USER_PASSWORD=password
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./configs:/opt/airflow/configs
      - ./data:/opt/airflow/data
      - ./models:/opt/airflow/models
      - ./mlruns:/opt/airflow/mlruns
    ports:
      - "8080:8080"
    command: airflow standalone
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  api:
    build:
      context: .
      target: development  # Use 'production' for prod deploy
    ports:
      - "8000:8000"
    environment:
      - MODEL_SOURCE=file                           # "file" or "mlflow"
      - MODEL_PATH=models/model.pkl                 # For file source
      - MLFLOW_MODEL_URI=models:/churn_predictor/latest  # For mlflow source
      - MLFLOW_TRACKING_URI=file:///app/mlruns
    volumes:
      - ./models:/app/models
      # - ./mlruns:/app/mlruns  # Only if MODEL_SOURCE=mlflow
      - ./src:/app/src          # Dev only - remove for production
      - ./configs:/app/configs
    depends_on:
      - airflow
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
